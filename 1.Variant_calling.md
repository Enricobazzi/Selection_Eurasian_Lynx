---
title: "Variant_calling"
author: "Enrico"
date: "16 March 2020"
output: html_document
---

After mapping to the Canada Lynx reference genomes I will proceed to call variants with the software GATK (version 4.1.4.1).

We will not go through a GVCF and will call variants directly to VCF format with Haplotypecaller.

This will be run on the CESGA ft2 server for faster execution, sbatching parallel jobs (1.Variant_calling-executables/per_CHR_Haplotype_caller.sh) for each chromosome.

In order to run the analysis separately for each chromosome I need to generate a BED file for each chromosome with its length, extracting this information from the FAI index file of the reference genome.
```
CHRarray=($(cat /mnt/lustre/scratch/home/csic/ebd/jg2/LL_selection/Ref_Genome_LyCa/lc4.fa.fai | cut -f 1))

for i in ${CHRarray[@]}
  do
  echo $i
  cat /mnt/lustre/scratch/home/csic/ebd/jg2/LL_selection/Ref_Genome_LyCa/lc4.fa.fai |
  grep -w "$i" |
  cut -f1,2 |
  awk 'BEGIN {FS="\t"; OFS="\t"} {print $1, 0, $2}' > \
  /mnt/lustre/scratch/home/csic/ebd/jg2/LL_selection/Ref_Genome_LyCa/CHR_BEDs/${i}_CHR_coordinates.bed
done
```
Now we are ready to sbatch our script for each chromosome. JobIDs will be stored in other file -> Variant_calling_jobIDs.txt (too many will make this file messy).
```
CHRarray=($(cat /mnt/lustre/scratch/home/csic/ebd/jg2/LL_selection/Ref_Genome_LyCa/lc4.fa.fai | cut -f 1))
for chr in ${CHRarray[@]}
 do
  echo "calling variants in ${chr}"
  sbatch per_CHR_Haplotype_caller.sh ${chr}
done
```
It seems some chromosomes are too big to process in just 4 days (CESGA time limit).
To get the list of the ones that are still running after one day (won't make it to time limit), I ran this:
```
for jobid in $(squeue | grep -v "JOBID" | cut -d' ' -f12)
 do
  grep -oE "/mnt/lustre/scratch/home/csic/ebd/jg2/LL_selection/Ref_Genome_LyCa/CHR_BEDs/.*_CHR_coordinates.bed" slurm-${jobid}.out
done | sort -u > Long_Scaffold.list
```
After canceling still running jobs, I will split the non-finished Scaffolds into much smaller units. This way, although limit of jobs that can be submitted is 100, I can submit shorter jobs (for fractions of scaffolds) continuously until I finish. To divide each scaffold into 10 equally sized windows, and each of those windows into 8 sub-windows (8_windows.bed) I used the following script:
```
mkdir Scaffold_Partitions
mv Long_Scaffold.list Scaffold_Partitions
for bed in $(cat Long_Scaffold.list)
 do
  scaffold=($(echo ${bed} | rev | cut -d'/' -f1 | rev | sed 's/_CHR_coordinates.bed//g'))
  echo "${scaffold}"
  bedtools makewindows -b ${bed} -n 10 > ${scaffold}_10_windows.bed

  for i in {1..10}
   do
    mkdir ${scaffold}_${i}
    awk -v LINE_NUMBER=${i} '{if(NR==LINE_NUMBER) print $0}' ${scaffold}_10_windows.bed > ${scaffold}_${i}/${scaffold}_w${i}.bed
    bedtools makewindows -b ${scaffold}_${i}/${scaffold}_w${i}.bed -n 8 > ${scaffold}_${i}/${scaffold}_w${i}_8_windows.bed

    for k in {1..8}
     do
      awk -v LINE_NUMBER=${k} '{if(NR==LINE_NUMBER) print $0}' ${scaffold}_${i}/${scaffold}_w${i}_8_windows.bed \
      > ${scaffold}_${i}/${scaffold}_w${i}_w${k}.bed
    done
  done
done
```
This gives us a total of 80 windows for each scaffold. The idea is to have a script (script1) that will sbatch a job (script2) for each 10 windows of a given scaffold. Script2 will use all of the computational power in the node (24 cores), to simultaneously run HaplotypeCaller for each of the 8 sub-windows of the given scaffold window. The final result will be that for one scaffold 10 jobs will be sbatched, and each of those jobs will be running 8 HaplotypeCallers.

Script 1 is : parallel_scaffold_sbatcher.sh
Script 2 is : parallel_HaplotypeCaller.sh

This means will produce lot of small final VCFs that will have to be concatenated.

To try it on just one window (1/10th) of a Scaffold I ran:
```
sbatch parallel_HaplotypeCaller.sh Super_Scaffold_1 1
Submitted batch job 3802811
```
It worked! I can submit up to 10 Scaffolds at the time. Again JobIDs will be stored in other file -> Variant_calling_jobIDs.txt.
```
LongScaffolds=($(cat Scaffold_Partitions/Long_Scaffold.list | rev | cut -d'/' -f1 | rev | sed 's/_CHR_coordinates.bed//'))

for scaffold in ${LongScaffolds[9]}
 do
  echo "${scaffold}"
  ./parallel_scaffold_sbatcher.sh ${scaffold}
done
```
